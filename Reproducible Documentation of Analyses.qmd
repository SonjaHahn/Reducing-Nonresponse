---
title: "Reproducible Documentation of Analyses"
author: "Sonja Hahn, Samuel Merk"
format: html
execute:
  cache: true
---

## Libraries
```{r loading libraries}
#| message: false
#| cache: false

library(tidyverse)
library(reactable)
library(naniar)
library(brms)
```


## Data Download

The raw data of the study blalablalba you can download it `r xfun::embed_file("data/eva_data_OEQexperimentI.csv", "eva_data_OEQexperimentI.csv", "here")` ...

Itemcodes:

```{r}
#| cache: false

read_csv("data/question_keys_data.csv") |> 
  reactable()

keys <- read.csv("data/question_keys_data.csv")
```


## Data Import
### Experiment 1
#### OEI data
```{r import the data}
#| cache: true

# raw data experiment 1 ########################################################
## import data from suf
data_s1 <- read_csv("data/eva_data_OEQexperimentI.csv")%>%
  mutate(answer_text_isna = is.na(answer_text),
         #die folgende Zeile macht effektiv das gleiche --> 
         ## ToDo: anpassen "sinnvolle Antwortlänge?" 
         answert_text_isna_or_length0 = ifelse(answer_text_isna == T, T,
                                         nchar(answer_text) == 0),
         no_oeq_answer = ifelse(question_id %in% c(47:48),
                                answer_text_isna, NA),
         question_id_fac = as.factor(question_id),
         position = ifelse(survey_id %in% c(2,3), 
                           "at the beginning", "at the end"),
         instruction = ifelse(survey_id %in% c(2,5),
                              "motivating instruction", "neutral instruction"),
         oeq_answerlengthifgiven = ifelse(no_oeq_answer == T, 
                                          NA, 
                                          nchar(answer_text)),
         oeq_answerlengthifgiven_log = log(oeq_answerlengthifgiven))%>%
  group_by(class_id, question_id)%>%
  mutate(oeq_answer_classprop = 1 - mean(no_oeq_answer, na.rm = T),
         oeq_answerlengthifgiven_perclass = 
           sum(nchar(answer_text), 
               na.rm = T)/(n()-sum(no_oeq_answer)))%>%
  ungroup()
```

# Datenexploration

```{r}
#| eval : false
View(data_s1)

names(data_s1)

data_s1 |> select(question_id, survey_id) |> table()


```



#### SEEQ data


```{r data-wrangling-s1-cfa-data}
#| cache: true

# pivoting to wide data frame with seeq data for CFA ##################################
# Due to technical issues there are some nonunique entries per student and variables
# These were remove with the following function
paste_na_function <- function(x) ifelse(length(unique(na.omit(x))) > 1, NA, mean(x))

data_s1_seeq <- data_s1%>%
  select(respondent_hash, answer_integer, class_id, teacher_id, question_id)%>%
  filter(question_id %in% c(1:20))%>%
  unique(.)%>%
  pivot_wider(
    names_from = question_id,
    values_from = answer_integer,
    values_fn = list(answer_integer = paste_na_function)
  )%>%
  mutate(v1 = `1`, v2 = `2`, v3 = `3`, v4 = `4`, v5 = `5`, v6 = `6`, v7 = `7`, 
         v8 = `8`, v9 = `9`, v10 = `10`, v11 = `11`, v12 = `12`, v13 = `13`, 
         v14 = `14`, v15 = `15`, v16 = `16`, v17 = `17`, v18 = `18`, v19 = `19`,
         v20 = `20`,
         Learning = rowMeans(data.frame(v1, v2, v3, v4), na.rm = T),
         Ethusiasm = rowMeans(data.frame(v5, v6, v7, v8), na.rm = T),
         Organisation = rowMeans(data.frame(v9, v10, v11, v12), na.rm = T),
         `Group Interaction` = rowMeans(data.frame(v14, v15, v16, v17), na.rm = T),
         `Individual Rapport` = rowMeans(data.frame(v18, v19, v20), na.rm = T))
```
ANMERKUNG (Sonja): Da sind weitere Items (ähnlich zum SEEQ) 
und auch Angaben zu Schule etc. - wurden die später gestellt?

## Recoding

Was zählt als **sinnvolle** Antwort?
```{r}
#| cache: true


data_s1 |> filter(question_id %in% c(45:48)) |> 
  select(answer_text) |> 
  unique() |> 
  mutate(l.answer = nchar(answer_text)) |> 
  filter(l.answer <= 20) |> 
  arrange(l.answer)  |>  View()


# Welche sollen herausgenommen werden?

# Zeichen
# Lösche alle - / * . ? * • - — # Vorgehen beim InDiKo-Bericht

del_character <- "[-/*.?*•—]"

data_s1 |> 
  mutate(answer_text_short = str_replace_all(answer_text, del_character, "")) |> 
  select(starts_with("answer_text")) |> View()

# Lange --> mit welcher Begründung ("nichts" vs. "Buch") 

# Inhaltlich ("nichts"?) (das hängt etwas von unseren Hypothesen ab)

# evtl. aufbereitete Antworten abspeichern


```
Oft steht sinngemäß "alles gut"

evtl. positive und negative Antworten zusammenfügen (Idee: Wenn alles gut war, 
sollte zumindest bei den positiven Aspekten was stehen); 
das vereinfacht evtl. auch die folgenden Analysen (Messwdh. als weiteres Level
in den Daten eliminiert)


Wer bricht SEEQ ab?
```{r}
# alle personen mit mindestens einem seeq item
data_s1 |> 
  select(completed_survey_id, question_id, answer_integer) |> 
  filter(question_id %in% c(1:20)) |> 
  na.omit() |> 
  select(completed_survey_id) |> 
  distinct()

# alle personen
data_s1 |> 
  select(completed_survey_id) |> 
  distinct()

# Missing auf einzelnen Variablen
data_s1_seeq |> 
  select(v1:v20) |> 
  gg_miss_var()
# Wollen wir da was machen, oder lediglich berichten (55/3163 sind recht wenig,
# zumal zwar eine Tendenz vorhanden ist, gegen Ende mehr auszulassen, aber
# das nicht komplett systematisch ist, Personen einfach weiterblättern können etc.)
```






## Deskriptive Analyse

Over all questions and experimental conditions, 
`r length(data_s1%>%filter(question_id %in% c(47,48) & no_oeq_answer == F)%>%.$answer_text)/data_s1%>%filter(question_id %in% c(47,48))%>%nrow()*100`% 
of students gave answers, which were at average `r table(nchar(data_s1%>%filter(no_oeq_answer == F)%>%.$answer_text))` characters long.


### Global Picture
```{r}
# no_oeq_answer: dichotomous
ggplot(
  data_s1 %>%
    filter(question_id %in% c(47, 48)),
  aes(position, as.numeric(no_oeq_answer), color = instruction)
) +
  stat_summary(position = position_dodge(width = 0.25)) +
    coord_cartesian(ylim = c(0, 1))

# no_oeq_answer: classwise aggregations
ggplot(
  data_s1 %>%
    filter(question_id %in% c(47, 48)),
  aes(position, as.numeric(oeq_answer_classprop), color = instruction)
) +
  stat_summary(position = position_dodge(width = 0.25)) 

# answertextlenth: level-1
ggplot(
  data_s1 %>%
    filter(question_id %in% c(47, 48)),
  aes(position, oeq_answerlengthifgiven_log, color = instruction)
) + geom_violin(fill = NA) +
  stat_summary(position = position_dodge(width = .9)) 

```

aktueller Plan: Grafiken beschrieben und daraus ableiten, weshalb die 
Mehrebenstruktur einfache approaches wie chi^2 oder MWU problematisch macht.

## Zero-Inlated Poisson-Regression

```{r}
# generate data
data_poisson <- 
  data_s1 %>% 
  filter(question_id %in% c(47, 48)) %>% 
  mutate(answerlength_incl_zero = ifelse(answer_text_isna == T, 0,
                                         ifelse(oeq_answerlengthifgiven == 1, 0, 
                                                oeq_answerlengthifgiven)))
# Das ergibt pro Item die Antwortlänge, d.h. noch geschachtelt in der Person



# look at the distribution
ggplot(data_poisson, aes(answerlength_incl_zero)) +
  geom_histogram(binwidth = 1)

ggplot(data_poisson, aes(answerlength_incl_zero)) +
  geom_density()

ggplot(data_poisson, aes(answerlength_incl_zero)) +
  geom_histogram(binwidth = 1) +
  coord_cartesian(xlim = c(0,50), ylim = c(0, 200))

ggplot(data_poisson, aes(answerlength_incl_zero)) +
  geom_histogram(binwidth = 1) +
  coord_cartesian(xlim = c(0,50), ylim = c(0, 400))+
  facet_wrap(vars(question_id)) 


mod0 <- brm(answerlength_incl_zero ~ 1 + (1|respondent_hash),
            family = zero_inflated_poisson(), # zero_inflated_poisson(link = "log", link_zi = "logit")
            data = data_poisson)

mod1 <- brm(answerlength_incl_zero ~ 1 + position + (1|respondent_hash),
            family = zero_inflated_poisson(),
            data = data_poisson)



sjPlot::tab_model(mod0, mod1)

# https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/monsters-and-mixtures.html#example-zero-inflated-poisson.
# Kein Multilevel

# b11.4 <- 
#   brm(data = d, family = zero_inflated_poisson,
#       Y ~ 1,
#       prior = c(prior(normal(0, 10), class = Intercept), # Poisson? lambda?
#                 prior(beta(2, 2), class = zi)),  # zi: ZeroInflated (p_i), default beta(1,1)
#       cores = 4,
#       seed = 11) 

# print(b11.4)

```

https://fcorowe.github.io/countdata_modelling/ 

Was mir an den folgenden Modellen noch nicht gefällt: 

1. könnte man evtl. auf die overdispersed distributions umsteigen, um zusätzliche Clusterungen abzufangen
What causes overdispersion? Overdispersion is caused by positive correlation between responses or by an excess variation between response probabilities or counts. Overdispersion also arises when there are violations in the distributional assumptions of the data, such as when the data are clustered and thereby violate the likelihood independence of observations assumption.--> Zero-inflated Negative Binomial regression; oder besser modellieren
2. sind keine uVs im zero-Inflation Teil drin.
```{r}
#| eval = FALSE

library(lme4)
library(merTools)
library(glmmTMB) # fitting generalised linear mixed models
library(bbmle)


# Owls <- transform(Owls,
#                   Nest = reorder(Nest,NegPerChick),
#                   NCalls = SiblingNegotiation,
#                   FT = FoodTreatment)
# 
# eq <- NCalls ~ (FT + ArrivalTime) * SexParent + offset( log( BroodSize)) + ( 1 | Nest)
# 
# zipoisson1 <- glmmTMB(eq,
#                       data=Owls,
#                       ziformula=~1,
#                       family=poisson)
# summary(zipoisson1)

mod_0 <- glmmTMB(answerlength_incl_zero ~ 1 +  (1|respondent_hash),
            data = data_poisson,
            ziformula =~ 1,
            family = poisson)

summary(mod_0)

mod_position <- glmmTMB(answerlength_incl_zero ~ 1 + position + (1|respondent_hash),
            data = data_poisson,
            ziformula =~ 1,
            family = poisson)

summary(mod_position)

mod_instruction <- glmmTMB(answerlength_incl_zero ~ 1 + instruction + (1|respondent_hash),
            data = data_poisson,
            ziformula =~ 1,
            family = poisson)

summary(mod_instruction)

mod_instruction_position <- glmmTMB(answerlength_incl_zero ~ 1 + instruction + position + (1|respondent_hash),
            data = data_poisson,
            ziformula =~ 1,
            family = poisson)

summary(mod_instruction_position)
```


https://fukamilab.github.io/BIO202/04-C-zero-data.html#zero-inflated_poisson_glm 
```{r}
library(pscl)
M3 <- zeroinfl(answerlength_incl_zero ~ instruction + position | ## Predictor for the Poisson process
                 1, ## Predictor for the Bernoulli process;
               dist = 'poisson',
               data = data_poisson |> filter(question_id == 47))


summary(M3)

M3 <- zeroinfl(answerlength_incl_zero ~ instruction + position | ## Predictor for the Poisson process
                 instruction + position, ## Predictor for the Bernoulli process;
               dist = 'poisson',
               data = data_poisson |> filter(question_id == 47))


summary(M3)

```



